{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "80eed9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re  # Asegúrate de importar re para el uso de regex en extract_positions\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from math import sqrt\n",
    "\n",
    "# Configurar las opciones de visualización de pandas (opcional)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Función para limpiar columnas numéricas\n",
    "def clean_numeric_column(column):\n",
    "    column_as_str = column.astype(str).str.replace(',', '').str.replace('$', '').str.strip()\n",
    "    return pd.to_numeric(column_as_str, errors='coerce')\n",
    "\n",
    "# Extracción de los rangos numéricos de 'Bid Strategy'\n",
    "def extract_positions(bid_strategy):\n",
    "    if pd.isna(bid_strategy):\n",
    "        return np.nan, np.nan\n",
    "    matches = re.findall(r'\\d+', bid_strategy)\n",
    "    if len(matches) >= 2:\n",
    "        return int(matches[0]), int(matches[1])\n",
    "    return np.nan, np.nan\n",
    "\n",
    "# Rutas completas a los archivos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Marcar los conjuntos de datos para poder distinguirlos después de la concatenación\n",
    "df_train['set'] = 'Not Kaggle'\n",
    "df_test['set'] = 'Kaggle'\n",
    "\n",
    "# Concatenar df_train y df_test en df_full\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True) \n",
    "\n",
    "columns_to_clean = ['Search Engine Bid', 'Impressions', 'Avg. Cost per Click', 'Avg. Pos.']\n",
    "for column in columns_to_clean:\n",
    "    df_full[column] = clean_numeric_column(df_full[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d0ca3",
   "metadata": {},
   "source": [
    "### 1. Preprocesamiento de Datos en el Dataset de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2a10ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limpieza y transformación antes de la división en conjuntos de entrenamiento y prueba\n",
    "df_train['Search Engine Bid'] = clean_numeric_column(df_train['Search Engine Bid'])\n",
    "df_train['Impressions'] = clean_numeric_column(df_train['Impressions'])\n",
    "df_train['Avg. Cost per Click'] = clean_numeric_column(df_train['Avg. Cost per Click'])\n",
    "df_train['Avg. Pos.'] = clean_numeric_column(df_train['Avg. Pos.'])\n",
    "\n",
    "df_test['Search Engine Bid'] = clean_numeric_column(df_test['Search Engine Bid'])\n",
    "df_test['Impressions'] = clean_numeric_column(df_test['Impressions'])\n",
    "df_test['Avg. Cost per Click'] = clean_numeric_column(df_test['Avg. Cost per Click'])\n",
    "df_test['Avg. Pos.'] = clean_numeric_column(df_test['Avg. Pos.'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d1feeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar One-Hot Encoding para 'Match Type' y cualquier otra variable categórica necesaria\n",
    "df_full['Match Type'].fillna('Unknown', inplace=True)\n",
    "categorical_cols = ['Match Type']\n",
    "df_full = pd.concat([df_full, pd.get_dummies(df_full[categorical_cols])], axis=1)\n",
    "df_full.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ecec5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar los NaNs restantes en las columnas numéricas con el método forward fill\n",
    "df_full.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "361c087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación en características y objetivo, seguido por la división en entrenamiento y prueba\n",
    "features_columns = ['Search Engine Bid', 'Impressions', 'Avg. Cost per Click', 'Avg. Pos.'] + [col for col in df_full.columns if col.startswith('Match Type_')]\n",
    "features = df_full[features_columns]\n",
    "target = df_full['Clicks']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b7327",
   "metadata": {},
   "source": [
    "### 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c36a6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625bb71",
   "metadata": {},
   "source": [
    "### 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c465c959",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2,577'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ya has importado DecisionTreeRegressor y sqrt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Entrenar un árbol de decisión\u001b[39;00m\n\u001b[0;32m      4\u001b[0m tree_model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m tree_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred_tree \u001b[38;5;241m=\u001b[39m tree_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1378\u001b[0m         X,\n\u001b[0;32m   1379\u001b[0m         y,\n\u001b[0;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\tree\\_classes.py:318\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m--> 318\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n\u001b[0;32m    320\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2,577'"
     ]
    }
   ],
   "source": [
    "# Ya has importado DecisionTreeRegressor y sqrt\n",
    "\n",
    "# Entrenar un árbol de decisión\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "rmse_tree = sqrt(mean_squared_error(y_test, y_pred_tree))\n",
    "print(f\"RMSE del Árbol de Decisión: {rmse_tree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2512d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
