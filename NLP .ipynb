{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12633758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con max_features=600, hay 2 características completamente ceros.\n",
      "Resumen de características completamente ceros por configuración de max_features: [(600, 2)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Convertir 'Keyword' a minúsculas\n",
    "df_train['Keyword'] = df_train['Keyword'].str.lower()\n",
    "df_test['Keyword'] = df_test['Keyword'].str.lower()\n",
    "\n",
    "# Función para limpiar columnas numéricas\n",
    "def clean_numeric_column(column):\n",
    "    column_as_str = column.astype(str).str.replace(',', '').str.replace('$', '').str.strip()\n",
    "    return pd.to_numeric(column_as_str, errors='coerce')\n",
    "\n",
    "# Limpiar las columnas numéricas\n",
    "columns_to_clean = ['Search Engine Bid', 'Impressions', 'Avg. Cost per Click', 'Avg. Pos.', 'Clicks']\n",
    "for column in columns_to_clean:\n",
    "    df_train[column] = clean_numeric_column(df_train[column])\n",
    "    if column != 'Clicks':  # 'Clicks' no está en df_test\n",
    "        df_test[column] = clean_numeric_column(df_test[column])\n",
    "\n",
    "# Reemplazar ceros en 'Impressions' para la transformación Box-Cox\n",
    "min_value = df_train.loc[df_train['Impressions'] > 0, 'Impressions'].min()\n",
    "df_train['Impressions'] = df_train['Impressions'].replace(0, min_value)\n",
    "fitted_lambda, _ = stats.boxcox(df_train.loc[df_train['Impressions'] > 0, 'Impressions'])\n",
    "df_train['Impressions'] = stats.boxcox(df_train['Impressions'], lmbda=fitted_lambda)\n",
    "\n",
    "# Visualizar los primeros registros del conjunto de entrenamiento\n",
    "df_train.head()\n",
    "\n",
    "\n",
    "\n",
    "# Después de haber convertido las matrices TF-IDF a DataFrames y concatenado con los conjuntos de datos originales\n",
    "\n",
    "print(f\"Con max_features={max_features}, hay {features_all_zero} características completamente ceros.\")\n",
    "\n",
    "# Al final, tienes un resumen de cuántas características completamente ceros hay para cada valor de max_features\n",
    "print(\"Resumen de características completamente ceros por configuración de max_features:\", features_all_zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e5e78b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de X_train procesado: (3528, 685)\n",
      "Dimensiones de X_val procesado: (882, 685)\n",
      "Primeras filas de X_train procesado:\n",
      "       Search Engine Bid  Impressions  Avg. Pos.  Avg. Cost per Click  2006  \\\n",
      "2588              10.00     4.606787       1.00                 0.28   0.0   \n",
      "2354               0.78     6.413341       2.45                 1.08   0.0   \n",
      "655                6.25     4.202726       1.05                 1.29   0.0   \n",
      "4339               0.13     6.155182       3.63                 0.35   0.0   \n",
      "3557               8.75     5.349669       1.14                 1.25   0.0   \n",
      "\n",
      "      abidjan  abou  aeroport  affaires  agadir  ...  Bid Strategy_nan  \\\n",
      "2588      0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "2354      0.0   0.0       0.0       0.0     0.0  ...                 0   \n",
      "655       0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "4339      0.0   0.0       0.0       0.0     0.0  ...                 0   \n",
      "3557      0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "\n",
      "      Status_Live  Status_Paused  Status_Unavailable  Status_Sent  \\\n",
      "2588            1              0                   0            0   \n",
      "2354            0              1                   0            0   \n",
      "655             1              0                   0            0   \n",
      "4339            0              1                   0            0   \n",
      "3557            0              1                   0            0   \n",
      "\n",
      "      Status_Deactivated     Campaign    Category  Publisher Name  \\\n",
      "2588                   0  2053.256568   99.388158       99.680786   \n",
      "2354                   0   129.108369  258.053092      169.516252   \n",
      "655                    0    44.555184   99.388158       34.952000   \n",
      "4339                   0   129.108369   64.309102       77.437653   \n",
      "3557                   0   129.108369   15.004962       77.437653   \n",
      "\n",
      "      Keyword Group  \n",
      "2588     717.290788  \n",
      "2354     129.108369  \n",
      "655       62.462685  \n",
      "4339     129.108369  \n",
      "3557     129.108369  \n",
      "\n",
      "[5 rows x 685 columns]\n",
      "Primeras filas de X_val procesado:\n",
      "       Search Engine Bid  Impressions  Avg. Pos.  Avg. Cost per Click  2006  \\\n",
      "1413               6.25     0.000000       1.00                 2.16   0.0   \n",
      "3352               7.50     0.000000       1.00                 0.13   0.0   \n",
      "3970               0.00     4.468347       1.61                 1.89   0.0   \n",
      "3629               6.25     4.626762       1.00                 1.42   0.0   \n",
      "144                6.25     2.412054       1.75                 3.75   0.0   \n",
      "\n",
      "      abidjan  abou  aeroport  affaires  agadir  ...  Bid Strategy_nan  \\\n",
      "1413      0.0   0.0       0.0       0.0     0.0  ...                 0   \n",
      "3352      0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "3970      0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "3629      0.0   0.0       0.0       0.0     0.0  ...                 1   \n",
      "144       0.0   0.0       0.0       0.0     0.0  ...                 0   \n",
      "\n",
      "      Status_Live  Status_Paused  Status_Unavailable  Status_Sent  \\\n",
      "1413            0              0                   1            0   \n",
      "3352            1              0                   0            0   \n",
      "3970            1              0                   0            0   \n",
      "3629            0              1                   0            0   \n",
      "144             0              1                   0            0   \n",
      "\n",
      "      Status_Deactivated    Campaign   Category  Publisher Name  Keyword Group  \n",
      "1413                   0    2.395837  99.388158       99.680786     104.496882  \n",
      "3352                   0   50.214896  99.388158       34.952000      88.371171  \n",
      "3970                   0  208.881857  99.388158      125.666677      21.927775  \n",
      "3629                   0    7.649128  99.388158       34.952000      91.031061  \n",
      "144                    0    5.593006  99.388158       99.680786      42.540723  \n",
      "\n",
      "[5 rows x 685 columns]\n",
      "Resumen estadístico de X_train procesado:\n",
      "        Search Engine Bid  Impressions    Avg. Pos.  Avg. Cost per Click  \\\n",
      "count        3528.000000  3528.000000  3528.000000          3528.000000   \n",
      "mean            5.439059     4.699488     1.912313             1.915057   \n",
      "std             3.290024     2.220292     1.063069             1.331682   \n",
      "min             0.000000     0.000000     0.000000             0.040000   \n",
      "25%             3.750000     3.097339     1.137500             0.840000   \n",
      "50%             6.250000     4.807327     1.580000             1.680000   \n",
      "75%             6.250000     6.193498     2.280000             2.700000   \n",
      "max            27.500000    12.811354    15.000000            10.000000   \n",
      "\n",
      "              2006      abidjan         abou     aeroport     affaires  \\\n",
      "count  3528.000000  3528.000000  3528.000000  3528.000000  3528.000000   \n",
      "mean      0.003682     0.000547     0.000200     0.000934     0.000189   \n",
      "std       0.039825     0.023003     0.011905     0.025185     0.011250   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       0.472763     1.000000     0.707107     0.822431     0.668226   \n",
      "\n",
      "            agadir  ...  Bid Strategy_nan  Status_Live  Status_Paused  \\\n",
      "count  3528.000000  ...       3528.000000  3528.000000    3528.000000   \n",
      "mean      0.000546  ...          0.268707     0.129252       0.568878   \n",
      "std       0.022951  ...          0.443350     0.335526       0.495303   \n",
      "min       0.000000  ...          0.000000     0.000000       0.000000   \n",
      "25%       0.000000  ...          0.000000     0.000000       0.000000   \n",
      "50%       0.000000  ...          0.000000     0.000000       1.000000   \n",
      "75%       0.000000  ...          1.000000     0.000000       1.000000   \n",
      "max       1.000000  ...          1.000000     1.000000       1.000000   \n",
      "\n",
      "       Status_Unavailable  Status_Sent  Status_Deactivated     Campaign  \\\n",
      "count         3528.000000  3528.000000         3528.000000  3528.000000   \n",
      "mean             0.250567     0.029762            0.021542   104.392495   \n",
      "std              0.433401     0.169954            0.145203   246.196182   \n",
      "min              0.000000     0.000000            0.000000     2.395837   \n",
      "25%              0.000000     0.000000            0.000000    12.482609   \n",
      "50%              0.000000     0.000000            0.000000    63.106280   \n",
      "75%              1.000000     0.000000            0.000000   129.108369   \n",
      "max              1.000000     1.000000            1.000000  2053.256568   \n",
      "\n",
      "          Category  Publisher Name  Keyword Group  \n",
      "count  3528.000000     3528.000000    3528.000000  \n",
      "mean    100.373654      104.493286     131.237848  \n",
      "std      72.399370       40.795212     260.103045  \n",
      "min      15.004962       34.952000      18.114646  \n",
      "25%      93.756325       77.437653      71.993080  \n",
      "50%      99.388158       99.680786      88.613186  \n",
      "75%      99.388158      131.846234     129.108369  \n",
      "max    1347.244999      169.516252    2277.737795  \n",
      "\n",
      "[8 rows x 685 columns]\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de tener los datos cargados y las columnas numéricas ya limpias y transformadas\n",
    "\n",
    "columns_to_drop = ['Clicks', 'entry_id']  # 'Keyword' solo se incluye si aún no se ha procesado\n",
    "\n",
    "# Eliminar las columnas que ya no se necesitan o que ya han sido procesadas\n",
    "if 'Keyword' not in df_train.columns:\n",
    "    columns_to_drop.append('Keyword')\n",
    "X = df_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "y = df_train['Clicks']\n",
    "\n",
    "# Asegúrate de que todas las columnas que se van a procesar con One-Hot Encoding o Target Encoding existen\n",
    "one_hot_cols = [col for col in ['Match Type', 'Bid Strategy', 'Status'] if col in X.columns]\n",
    "target_encode_cols = [col for col in ['Campaign', 'Category', 'Publisher Name', 'Keyword Group'] if col in X.columns]\n",
    "\n",
    "# Aplicar One-Hot Encoding a variables con pocas categorías\n",
    "one_hot_cols = ['Match Type', 'Bid Strategy', 'Status']\n",
    "one_hot_encoder = OneHotEncoder(cols=one_hot_cols, use_cat_names=True)\n",
    "X_train_one_hot = one_hot_encoder.fit_transform(X_train[one_hot_cols])\n",
    "X_val_one_hot = one_hot_encoder.transform(X_val[one_hot_cols])\n",
    "\n",
    "# Aplicar Target Encoding a variables con un número moderado de categorías\n",
    "target_encode_cols = ['Campaign', 'Category', 'Publisher Name', 'Keyword Group']\n",
    "target_encoder = TargetEncoder(cols=target_encode_cols)\n",
    "X_train_target_encoded = target_encoder.fit_transform(X_train[target_encode_cols], y_train)\n",
    "X_val_target_encoded = target_encoder.transform(X_val[target_encode_cols])\n",
    "\n",
    "# Unir las transformaciones con el resto de datos (excluyendo las columnas originales que ya han sido codificadas)\n",
    "X_train_processed = X_train.drop(one_hot_cols + target_encode_cols, axis=1).join(X_train_one_hot).join(X_train_target_encoded)\n",
    "X_val_processed = X_val.drop(one_hot_cols + target_encode_cols, axis=1).join(X_val_one_hot).join(X_val_target_encoded)\n",
    "\n",
    "# Ahora X_train_processed y X_val_processed están listos para ser usados en el modelado\n",
    "\n",
    "print(\"Dimensiones de X_train procesado:\", X_train_processed.shape)\n",
    "print(\"Dimensiones de X_val procesado:\", X_val_processed.shape)\n",
    "\n",
    "print(\"Primeras filas de X_train procesado:\\n\", X_train_processed.head())\n",
    "print(\"Primeras filas de X_val procesado:\\n\", X_val_processed.head())\n",
    "\n",
    "print(\"Resumen estadístico de X_train procesado:\\n\", X_train_processed.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab1a2e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Match Type después de One-Hot Encoding: 5\n",
      "Valores únicos en Bid Strategy después de One-Hot Encoding: 9\n",
      "Valores únicos en Status después de One-Hot Encoding: 5\n",
      "Valores únicos en Campaign después de Target Encoding en entrenamiento: 24\n",
      "Valores únicos en Campaign después de Target Encoding en validación: 23\n",
      "Valores únicos en Category después de Target Encoding en entrenamiento: 93\n",
      "Valores únicos en Category después de Target Encoding en validación: 72\n",
      "Valores únicos en Publisher Name después de Target Encoding en entrenamiento: 7\n",
      "Valores únicos en Publisher Name después de Target Encoding en validación: 7\n",
      "Valores únicos en Keyword Group después de Target Encoding en entrenamiento: 187\n",
      "Valores únicos en Keyword Group después de Target Encoding en validación: 148\n"
     ]
    }
   ],
   "source": [
    "# Para One-Hot Encoding\n",
    "for col in one_hot_cols:\n",
    "    print(f\"Valores únicos en {col} después de One-Hot Encoding:\", len(X_train_processed.filter(like=col).columns))\n",
    "\n",
    "# Para Target Encoding\n",
    "for col in target_encode_cols:\n",
    "    print(f\"Valores únicos en {col} después de Target Encoding en entrenamiento:\", X_train_processed[col].nunique())\n",
    "    print(f\"Valores únicos en {col} después de Target Encoding en validación:\", X_val_processed[col].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3305396",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1320 elements, new values have 662 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m model_pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Evaluar el pipeline con los datos de validación\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     44\u001b[0m rmse_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_val, y_pred_val))\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE en validación: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\pipeline.py:602\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1014\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1014\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_func_on_transformers(\n\u001b[0;32m   1015\u001b[0m     X,\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1017\u001b[0m     _transform_one,\n\u001b[0;32m   1018\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m   1019\u001b[0m     routed_params\u001b[38;5;241m=\u001b[39mrouted_params,\n\u001b[0;32m   1020\u001b[0m )\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:823\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    811\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    812\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    813\u001b[0m             delayed(func)(\n\u001b[0;32m    814\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m             )\n\u001b[0;32m    821\u001b[0m         )\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(jobs)\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\pipeline.py:1283\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params):\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m \n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:292\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m same_feature_names_in_out \u001b[38;5;129;01mor\u001b[39;00m not_all_str_columns:\n\u001b[0;32m    291\u001b[0m     adapter \u001b[38;5;241m=\u001b[39m _get_adapter_from_container(out)\n\u001b[1;32m--> 292\u001b[0m     out \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39mcreate_container(\n\u001b[0;32m    293\u001b[0m         X_output\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m    294\u001b[0m         X_original\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m    295\u001b[0m         columns\u001b[38;5;241m=\u001b[39mfeature_names_out,\n\u001b[0;32m    296\u001b[0m         inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output generated by `func` have different column names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the ones provided by `get_feature_names_out`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare set to the names provided by `get_feature_names_out`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:134\u001b[0m, in \u001b[0;36mPandasAdapter.create_container\u001b[1;34m(self, X_output, X_original, columns, inplace)\u001b[0m\n\u001b[0;32m    131\u001b[0m     X_output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_output, index\u001b[38;5;241m=\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m inplace)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrename_columns(X_output, columns)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_output\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:144\u001b[0m, in \u001b[0;36mPandasAdapter.rename_columns\u001b[1;34m(self, X, columns)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename_columns\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, columns):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# we cannot use `rename` since it takes a dictionary and at this stage we have\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# potentially duplicate column names in `X`\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     X\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\core\\generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\core\\generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\core\\internals\\base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1320 elements, new values have 662 elements"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Identificar columnas para cada tipo de encoding\n",
    "one_hot_cols = ['Match Type', 'Bid Strategy', 'Status']\n",
    "target_encode_cols = ['Campaign', 'Category', 'Publisher Name', 'Keyword Group']\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df_train.drop(columns=['Clicks', 'entry_id', 'Keyword'], errors='ignore')\n",
    "y = df_train['Clicks']\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Preparar el ColumnTransformer con OneHotEncoder y TargetEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', SklearnOneHotEncoder(), one_hot_cols),\n",
    "        ('target', ce.TargetEncoder(), target_encode_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Crear el pipeline con el preprocesador y el modelo\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline con los datos de entrenamiento\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el pipeline con los datos de validación\n",
    "y_pred_val = model_pipeline.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "print(f\"RMSE en validación: {rmse_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b2a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
