{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da56a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.535e+08, tolerance: 3.574e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 2.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso CV RMSE: 1003.6780755668896\n",
      "Lasso Validation RMSE: 2363.35520979625\n",
      "Ridge CV RMSE: 1003.705268703985\n",
      "Ridge Validation RMSE: 2363.284479968986\n",
      "Random Forest CV RMSE: 744.6274038632181\n",
      "Random Forest Validation RMSE: 993.5575819525551\n",
      "Gradient Boosting CV RMSE: 938.9119927630569\n",
      "Gradient Boosting Validation RMSE: 997.5700009870976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Preprocesamiento de las columnas numéricas\n",
    "def preprocess_numeric(df):\n",
    "    for col in ['Search Engine Bid', 'Avg. Pos.', 'Impressions']:\n",
    "        # Asegurar la correcta conversión de tipos de datos\n",
    "        df[col] = df[col].astype(str).str.replace('$', '').str.replace(',', '').str.strip().replace('', np.nan)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "df_train = preprocess_numeric(df_train)\n",
    "df_test = preprocess_numeric(df_test)\n",
    "\n",
    "# Imputar los valores faltantes después de la conversión\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "cols_to_impute = ['Impressions', 'Search Engine Bid', 'Avg. Pos.']\n",
    "\n",
    "df_train[cols_to_impute] = imputer.fit_transform(df_train[cols_to_impute])\n",
    "df_test[cols_to_impute] = imputer.transform(df_test[cols_to_impute])\n",
    "\n",
    "# Creación de características polinómicas\n",
    "poly_features = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(df_train[['Search Engine Bid', 'Impressions', 'Avg. Pos.']])\n",
    "X_test_poly = poly_features.transform(df_test[['Search Engine Bid', 'Impressions', 'Avg. Pos.']])\n",
    "\n",
    "# Separación de la variable objetivo\n",
    "y = df_train['Clicks'].str.replace(',', '').astype(float)  # Limpiar la columna 'Clicks' y convertir a float\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definición y entrenamiento de modelos\n",
    "models = {\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'Ridge': Ridge(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(f'{name} CV RMSE:', np.sqrt(-cv_score.mean()))\n",
    "    \n",
    "    # Evaluación en el conjunto de validación\n",
    "    valid_preds = model.predict(X_valid)\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_preds))\n",
    "    print(f'{name} Validation RMSE:', valid_rmse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8cd9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Train RMSE: 710.8267113116418\n",
      "Random Forest - Validation RMSE: 889.828742298982\n",
      "Random Forest - Best CV RMSE: 815.931420189223\n",
      "Gradient Boosting - Train RMSE: 614.7444996140088\n",
      "Gradient Boosting - Validation RMSE: 991.1386551971354\n",
      "Gradient Boosting - Best CV RMSE: 976.508363744101\n",
      "XGBoost - Train RMSE: 694.7252892883128\n",
      "XGBoost - Validation RMSE: 1255.4107302307755\n",
      "XGBoost - Best CV RMSE: 823.2820442772479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 3528, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 104.496882\n",
      "LightGBM - Train RMSE: 884.3843779464726\n",
      "LightGBM - Validation RMSE: 732.0301506102073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)  # Asume que X_train ya está definido\n",
    "X_valid_pca = pca.transform(X_valid)  # Asume que X_valid ya está definido\n",
    "\n",
    "# Ajuste de Hiperparámetros de Random Forest\n",
    "param_distributions_rf = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [None, 10, 20],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4]  \n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_distributions=param_distributions_rf,\n",
    "    n_iter=20, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search_rf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Hiperparámetros y RMSE para Random Forest\n",
    "rf_best_model = random_search_rf.best_estimator_\n",
    "rf_train_preds = rf_best_model.predict(X_train_pca)\n",
    "rf_valid_preds = rf_best_model.predict(X_valid_pca)\n",
    "\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_preds))\n",
    "rf_valid_rmse = np.sqrt(mean_squared_error(y_valid, rf_valid_preds))\n",
    "\n",
    "print(\"Random Forest - Train RMSE:\", rf_train_rmse)\n",
    "print(\"Random Forest - Validation RMSE:\", rf_valid_rmse)\n",
    "print(\"Random Forest - Best CV RMSE:\", np.sqrt(-random_search_rf.best_score_))\n",
    "\n",
    "# Ajuste de Hiperparámetros de Gradient Boosting\n",
    "param_distributions_gb = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],  \n",
    "}\n",
    "\n",
    "random_search_gb = RandomizedSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    param_distributions=param_distributions_gb,\n",
    "    n_iter=20, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search_gb.fit(X_train_pca, y_train)\n",
    "\n",
    "# Hiperparámetros y RMSE para Gradient Boosting\n",
    "gb_best_model = random_search_gb.best_estimator_\n",
    "gb_train_preds = gb_best_model.predict(X_train_pca)\n",
    "gb_valid_preds = gb_best_model.predict(X_valid_pca)\n",
    "\n",
    "gb_train_rmse = np.sqrt(mean_squared_error(y_train, gb_train_preds))\n",
    "gb_valid_rmse = np.sqrt(mean_squared_error(y_valid, gb_valid_preds))\n",
    "\n",
    "print(\"Gradient Boosting - Train RMSE:\", gb_train_rmse)\n",
    "print(\"Gradient Boosting - Validation RMSE:\", gb_valid_rmse)\n",
    "print(\"Gradient Boosting - Best CV RMSE:\", np.sqrt(-random_search_gb.best_score_))\n",
    "\n",
    "# Ajuste de Hiperparámetros de XGBoost\n",
    "param_distributions_xgb = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],  \n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    XGBRegressor(random_state=42),\n",
    "    param_distributions=param_distributions_xgb,\n",
    "    n_iter=20, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search_xgb.fit(X_train_pca, y_train)\n",
    "\n",
    "# Hiperparámetros y RMSE para XGBoost\n",
    "xgb_best_model = random_search_xgb.best_estimator_\n",
    "xgb_train_preds = xgb_best_model.predict(X_train_pca)\n",
    "xgb_valid_preds = xgb_best_model.predict(X_valid_pca)\n",
    "\n",
    "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_train_preds))\n",
    "xgb_valid_rmse = np.sqrt(mean_squared_error(y_valid, xgb_valid_preds))\n",
    "\n",
    "print(\"XGBoost - Train RMSE:\", xgb_train_rmse)\n",
    "print(\"XGBoost - Validation RMSE:\", xgb_valid_rmse)\n",
    "print(\"XGBoost - Best CV RMSE:\", np.sqrt(-random_search_xgb.best_score_))\n",
    "\n",
    "# Early Stopping para LightGBM\n",
    "lgbm_model = LGBMRegressor(n_estimators=10000, random_state=42)\n",
    "lgbm_model.fit(X_train_pca, y_train, eval_set=[(X_valid_pca, y_valid)], eval_metric='rmse')\n",
    "\n",
    "# RMSE para LightGBM\n",
    "lgbm_train_preds = lgbm_model.predict(X_train_pca)\n",
    "lgbm_valid_preds = lgbm_model.predict(X_valid_pca)\n",
    "\n",
    "lgbm_train_rmse = np.sqrt(mean_squared_error(y_train, lgbm_train_preds))\n",
    "lgbm_valid_rmse = np.sqrt(mean_squared_error(y_valid, lgbm_valid_preds))\n",
    "\n",
    "print(\"LightGBM - Train RMSE:\", lgbm_train_rmse)\n",
    "print(\"LightGBM - Validation RMSE:\", lgbm_valid_rmse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16704227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 3528, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 104.496882\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 3528, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 104.496882\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 107.041460\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 103.427356\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 106.165840\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2823, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 93.506908\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2823, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 112.343960\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 107.041460\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 116.211342\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 95.443066\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 114.848539\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 92.651461\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 116.051816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 103.427356\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 104.317678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 102.817900\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 110.331709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 88.134632\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 111.534987\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 106.165840\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 107.741693\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2257, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 115.948161\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 100.629761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 91.557130\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 114.957484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2823, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 93.506908\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 91.914526\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 100.117360\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 84.122675\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2259, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 92.243913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2259, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 99.134130\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2823, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 112.343960\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 115.465013\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 123.667848\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 107.673162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2259, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 112.794157\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2259, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 102.123949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Stacked Model CV RMSE: 915.3231540985412\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Stacked Model Validation RMSE: 951.3687433799953\n",
      "XGBoost Train RMSE: 697.1398548497748\n",
      "XGBoost Validation RMSE: 1324.412866893008\n",
      "Difference between XGBoost Train and Validation RMSE: 627.2730120432332\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "LightGBM Train RMSE: 884.6430228825426\n",
      "LightGBM Validation RMSE: 731.5518630462251\n",
      "Difference between LightGBM Train and Validation RMSE: 153.0911598363175\n",
      "Difference between Stacked Model CV RMSE and Validation RMSE: 36.04558928145411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Ajuste fino de hiperparámetros para Gradient Boosting (XGBoost)\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'colsample_bytree': [0.5, 0.7, 1]\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(XGBRegressor(n_estimators=100, random_state=42), param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train_pca, y_train)\n",
    "\n",
    "# Ajuste fino de hiperparámetros para LightGBM\n",
    "param_grid_lgbm = {\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'min_data_in_leaf': [20, 50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'colsample_bytree': [0.5, 0.7, 1]\n",
    "}\n",
    "grid_search_lgbm = GridSearchCV(LGBMRegressor(n_estimators=100, random_state=42), param_grid=param_grid_lgbm, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_lgbm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Control del sobreajuste: Ensemble de modelos\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "best_lgbm_model = grid_search_lgbm.best_estimator_\n",
    "\n",
    "estimators = [('xgb', best_xgb_model), ('lgbm', best_lgbm_model)]\n",
    "stacked_model = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "stacked_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluación con Validación Cruzada\n",
    "cv_score_stacked = cross_val_score(stacked_model, X_train_pca, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Stacked Model CV RMSE:\", np.sqrt(-cv_score_stacked.mean()))\n",
    "\n",
    "# Predicción en el conjunto de validación\n",
    "stacked_valid_preds = stacked_model.predict(X_valid_pca)\n",
    "stacked_valid_rmse = np.sqrt(mean_squared_error(y_valid, stacked_valid_preds))\n",
    "print(\"Stacked Model Validation RMSE:\", stacked_valid_rmse)\n",
    "\n",
    "# Diferencia entre RMSE de entrenamiento y validación\n",
    "xgb_train_preds = best_xgb_model.predict(X_train_pca)\n",
    "xgb_valid_preds = best_xgb_model.predict(X_valid_pca)\n",
    "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_train_preds))\n",
    "xgb_valid_rmse = np.sqrt(mean_squared_error(y_valid, xgb_valid_preds))\n",
    "print(\"XGBoost Train RMSE:\", xgb_train_rmse)\n",
    "print(\"XGBoost Validation RMSE:\", xgb_valid_rmse)\n",
    "print(\"Difference between XGBoost Train and Validation RMSE:\", abs(xgb_train_rmse - xgb_valid_rmse))\n",
    "\n",
    "lgbm_train_preds = best_lgbm_model.predict(X_train_pca)\n",
    "lgbm_valid_preds = best_lgbm_model.predict(X_valid_pca)\n",
    "lgbm_train_rmse = np.sqrt(mean_squared_error(y_train, lgbm_train_preds))\n",
    "lgbm_valid_rmse = np.sqrt(mean_squared_error(y_valid, lgbm_valid_preds))\n",
    "print(\"LightGBM Train RMSE:\", lgbm_train_rmse)\n",
    "print(\"LightGBM Validation RMSE:\", lgbm_valid_rmse)\n",
    "print(\"Difference between LightGBM Train and Validation RMSE:\", abs(lgbm_train_rmse - lgbm_valid_rmse))\n",
    "\n",
    "stacked_train_rmse = np.sqrt(-cv_score_stacked.mean())\n",
    "print(\"Difference between Stacked Model CV RMSE and Validation RMSE:\", abs(stacked_train_rmse - stacked_valid_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1af10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Archivo de submission creado: lgbm_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de prueba desde un archivo CSV\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Preprocesamiento de las columnas numéricas en los datos de prueba\n",
    "df_test = preprocess_numeric(df_test)\n",
    "\n",
    "# Aplicar las mismas transformaciones al conjunto de datos de prueba que se aplicaron al conjunto de entrenamiento\n",
    "X_test_poly = poly_features.transform(df_test[['Search Engine Bid', 'Impressions', 'Avg. Pos.']])\n",
    "\n",
    "# Aplicar PCA al conjunto de datos de prueba\n",
    "X_test_pca = pca.transform(X_test_poly)  # Asumiendo que 'pca' ya está definido\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de datos de prueba utilizando el modelo entrenado\n",
    "y_pred_test_lgbm = best_lgbm_model.predict(X_test_pca)\n",
    "\n",
    "# Crear el DataFrame para el envío\n",
    "submission_lgbm = pd.DataFrame({\n",
    "    'entry_id': df_test['entry_id'],  # Asegúrate de que 'entry_id' está en el conjunto de prueba\n",
    "    'Clicks': y_pred_test_lgbm\n",
    "})\n",
    "\n",
    "# Exportar el DataFrame a un archivo CSV para el envío\n",
    "submission_filename_lgbm = 'lgbm_submission.csv'\n",
    "submission_lgbm.to_csv(submission_filename_lgbm, index=False)\n",
    "\n",
    "print(f\"Archivo de submission creado: {submission_filename_lgbm}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff1e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
