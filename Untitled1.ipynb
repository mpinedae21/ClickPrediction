{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af7d70a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           DateHour  Temperature(F)  Humidity(%)  Wind speed (mph)  Visibility(miles)  DewPointTemperature(F)  Rainfall(in)  Snowfall(in)  SolarRadiation(MJ/m2) Holiday FunctioningDay  RENTALS         set\n",
      "ID                                                                                                                                                                                                                          \n",
      "mb_1039  2023-10-14 05:59:54.810000              52           81               0.4                2.9                    46.4           0.0           0.0                   0.00      No            Yes    519.0  Not Kaggle\n",
      "mb_1330  2023-10-26 08:59:53.355000              51           53               2.2                NaN                    35.2           0.0           0.0                   1.01      No            Yes   1251.0  Not Kaggle\n",
      "mb_551   2023-09-23 21:59:57.250000              56           49               2.5                3.4                    38.8           0.0           0.0                   0.00      No            Yes   1685.0  Not Kaggle\n",
      "mb_2103         2023-12-19 14:00:00              69           32               9.8               12.4                    38.7           0.0           0.0                   2.36      No             No      0.0  Not Kaggle\n",
      "mb_1430  2023-10-30 12:59:52.855000              53           20               2.9               10.8                    12.9           0.0           0.0                   1.96      No            Yes    814.0  Not Kaggle\n"
     ]
    }
   ],
   "source": [
    "## importing libraries ##\n",
    "\n",
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Setting pandas print options (optional but useful for large dataframes)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "## importing data ##\n",
    "\n",
    "file_path = './datasets/chicago_training_data.xlsx'\n",
    "\n",
    "# Reading training data into Python\n",
    "modeling_data = './datasets/train.xlsx'\n",
    "df_train = pd.read_excel(io=modeling_data, sheet_name='data', header=0, index_col='ID')\n",
    "\n",
    "# Reading testing data into Python\n",
    "testing_data = './datasets/test.xlsx'\n",
    "df_test = pd.read_excel(io=testing_data, sheet_name='data', header=0, index_col='ID')\n",
    "\n",
    "# Concatenating datasets together for missing value analysis and feature engineering\n",
    "df_train['set'] = 'Not Kaggle'\n",
    "df_test['set'] = 'Kaggle'\n",
    "\n",
    "# Concatenating both datasets together for MV analysis and feature engineering\n",
    "df_full = pd.concat(objs=[df_train, df_test], axis=0, ignore_index=False)\n",
    "\n",
    "# Checking the concatenated data\n",
    "print(df_full.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a921714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadiendo características de interacción iniciales\n",
    "X_train['Temp_Humidity'] = X_train['Temperature(F)'] * X_train['Humidity(%)']\n",
    "X_train['Temp_Hour'] = X_train['Temperature(F)'] * X_train['hour']\n",
    "X_test['Temp_Hour'] = X_test['Temperature(F)'] * X_test['hour']\n",
    "\n",
    "X_train['Visibility_Solar'] = X_train['Visibility(miles)'] * X_train['SolarRadiation(MJ/m2)']\n",
    "X_test['Visibility_Solar'] = X_test['Visibility(miles)'] * X_test['SolarRadiation(MJ/m2)']\n",
    "\n",
    "X_train['Weekday'] = (X_train['dayofweek'] >= 5).astype(int)\n",
    "X_test['Weekday'] = (X_test['dayofweek'] >= 5).astype(int)\n",
    "X_train['Solar_Weekday'] = X_train['SolarRadiation(MJ/m2)'] * X_train['Weekday']\n",
    "X_test['Solar_Weekday'] = X_test['SolarRadiation(MJ/m2)'] * X_test['Weekday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "413a858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadiendo nuevas características de interacción\n",
    "X_train['Wind_Humidity'] = X_train['Wind speed (mph)'] * X_train['Humidity(%)']\n",
    "X_test['Wind_Humidity'] = X_test['Wind speed (mph)'] * X_test['Humidity(%)']\n",
    "\n",
    "X_train['Temp_Visibility'] = X_train['Temperature(F)'] * X_train['Visibility(miles)']\n",
    "X_test['Temp_Visibility'] = X_test['Temperature(F)'] * X_test['Visibility(miles)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cc73e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Temp_Humidity    Temp_Hour  Visibility_Solar  Solar_Weekday\n",
      "count    1638.000000  1090.000000       1499.000000    1558.000000\n",
      "mean     3358.623321   706.673394          5.284776       0.098273\n",
      "std      1230.587843   457.736911          8.491600       0.399466\n",
      "min       600.000000     0.000000          0.000000       0.000000\n",
      "25%      2537.000000   276.000000          0.000000       0.000000\n",
      "50%      3240.000000   741.000000          0.000000       0.000000\n",
      "75%      4070.750000  1061.500000          7.757000       0.000000\n",
      "max      7178.000000  1725.000000         37.448000       3.020000\n",
      "Temp_Humidity      -0.168299\n",
      "Temp_Hour           0.468755\n",
      "Visibility_Solar    0.177665\n",
      "Solar_Weekday       0.083297\n",
      "Name: RENTALS, dtype: float64\n",
      "Temp_Humidity - Max value: 7178, Min value: 600\n",
      "Temp_Hour - Max value: 1725.0, Min value: 0.0\n",
      "Visibility_Solar - Max value: 37.448, Min value: 0.0\n",
      "Solar_Weekday - Max value: 3.02, Min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Recuerda que X_train y X_test deben estar ya definidos y contener las columnas originales\n",
    "\n",
    "# 1. Interacción entre temperatura y humedad\n",
    "X_train['Temp_Humidity'] = X_train['Temperature(F)'] * X_train['Humidity(%)']\n",
    "X_test['Temp_Humidity'] = X_test['Temperature(F)'] * X_test['Humidity(%)']\n",
    "\n",
    "# 2. Interacción entre temperatura y hora del día\n",
    "X_train['Temp_Hour'] = X_train['Temperature(F)'] * X_train['hour']\n",
    "X_test['Temp_Hour'] = X_test['Temperature(F)'] * X_test['hour']\n",
    "\n",
    "# 3. Interacción entre la visibilidad y la luz solar\n",
    "X_train['Visibility_Solar'] = X_train['Visibility(miles)'] * X_train['SolarRadiation(MJ/m2)']\n",
    "X_test['Visibility_Solar'] = X_test['Visibility(miles)'] * X_test['SolarRadiation(MJ/m2)']\n",
    "\n",
    "# 4. Efecto del día de la semana en la radiación solar\n",
    "# Creando una característica categórica para día laborable (0) vs. fin de semana (1)\n",
    "X_train['Weekday'] = (X_train['dayofweek'] >= 5).astype(int)\n",
    "X_test['Weekday'] = (X_test['dayofweek'] >= 5).astype(int)\n",
    "X_train['Solar_Weekday'] = X_train['SolarRadiation(MJ/m2)'] * X_train['Weekday']\n",
    "X_test['Solar_Weekday'] = X_test['SolarRadiation(MJ/m2)'] * X_test['Weekday']\n",
    "\n",
    "\n",
    "# Estadísticas descriptivas de las nuevas características\n",
    "new_features = ['Temp_Humidity', 'Temp_Hour', 'Visibility_Solar', 'Solar_Weekday']\n",
    "print(X_train[new_features].describe())\n",
    "\n",
    "# Asumiendo que y_train es una Serie de pandas con el mismo índice que X_train\n",
    "# Primero, agregamos 'RENTALS' temporalmente al DataFrame para calcular correlaciones\n",
    "X_train_with_target = X_train.copy()\n",
    "X_train_with_target['RENTALS'] = y_train\n",
    "\n",
    "# Calculamos las correlaciones\n",
    "correlations = X_train_with_target[new_features + ['RENTALS']].corr()\n",
    "\n",
    "# Imprimimos las correlaciones de las nuevas características con 'RENTALS'\n",
    "print(correlations['RENTALS'].drop('RENTALS'))\n",
    "\n",
    "# Identificación de valores atípicos en las nuevas características\n",
    "for feature in new_features:\n",
    "    print(f\"{feature} - Max value: {X_train[feature].max()}, Min value: {X_train[feature].min()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1822f9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN R² score: 0.6741348186011191\n",
      "Decision Tree R² score: 0.605845117113854\n",
      "Linear Regression R² score: 0.514432049992054\n",
      "Lasso Regression best R² score: 0.5151522862869492\n",
      "Best parameters for Lasso: {'lasso__alpha': 10}\n",
      "Ridge Regression best R² score: 0.5146916274090794\n",
      "Best parameters for Ridge: {'ridge__alpha': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regression best R² score: -1.409217925727069\n",
      "Best parameters for Elastic Net: {'elastic_net__alpha': 0.001, 'elastic_net__l1_ratio': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Ingeniería de características ##\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "## Ingeniería de características y Preparación de Datos ##\n",
    "\n",
    "# Asumiendo que df_train y df_test ya están definidos correctamente\n",
    "df_full = pd.concat(objs=[df_train, df_test], axis=0, ignore_index=False)\n",
    "\n",
    "# Conversión de 'DateHour' a datetime y extracción de características temporales\n",
    "df_full['DateHour'] = pd.to_datetime(df_full['DateHour'], errors='coerce')\n",
    "df_full['year'] = df_full['DateHour'].dt.year\n",
    "df_full['month'] = df_full['DateHour'].dt.month\n",
    "df_full['day'] = df_full['DateHour'].dt.day\n",
    "df_full['hour'] = df_full['DateHour'].dt.hour\n",
    "df_full['dayofweek'] = df_full['DateHour'].dt.dayofweek\n",
    "\n",
    "# Codificación One-Hot para 'Holiday' y 'FunctioningDay'\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_features = encoder.fit_transform(df_full[['Holiday', 'FunctioningDay']])\n",
    "encoded_features_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Holiday', 'FunctioningDay']), index=df_full.index)\n",
    "\n",
    "# Combinación de las nuevas columnas codificadas y eliminación de las originales\n",
    "df_full = pd.concat([df_full.drop(['Holiday', 'FunctioningDay'], axis=1), encoded_features_df], axis=1)\n",
    "\n",
    "# Separación de los datos en conjuntos de entrenamiento y prueba\n",
    "df_train_processed = df_full[df_full['set'] == 'Not Kaggle'].drop(['set', 'DateHour'], axis=1)\n",
    "df_test_processed = df_full[df_full['set'] == 'Kaggle'].drop(['set', 'DateHour', 'RENTALS'], axis=1)\n",
    "\n",
    "# Definición de X_train, X_test, y y_train\n",
    "X_train = df_train_processed.drop('RENTALS', axis=1)\n",
    "y_train = df_train_processed['RENTALS']\n",
    "X_test = df_test_processed\n",
    "\n",
    "## Definición y Ajuste de Modelos ##\n",
    "\n",
    "# K-Nearest Neighbors Regressor\n",
    "knn_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),  # Imputación de valores faltantes\n",
    "    StandardScaler(),  # Estandarización de características\n",
    "    KNeighborsRegressor(n_neighbors=7, weights='distance', metric='manhattan')\n",
    ")\n",
    "knn_pipeline.fit(X_train, y_train)  # Ajuste del pipeline con datos de entrenamiento\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(ccp_alpha=0.1, max_depth=8, min_samples_leaf=5, min_samples_split=3, random_state=42)\n",
    "dt_model.fit(X_train, y_train)  # Ajuste del modelo con datos de entrenamiento\n",
    "\n",
    "## Evaluación con Validación Cruzada ##\n",
    "knn_scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "dt_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"KNN R² score:\", np.mean(knn_scores))\n",
    "print(\"Decision Tree R² score:\", np.mean(dt_scores))\n",
    "\n",
    "# Linear Regression\n",
    "lr_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),  # Imputación de valores faltantes\n",
    "    StandardScaler(),  # Estandarización de características\n",
    "    LinearRegression()  # Modelo de regresión lineal\n",
    ")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_scores = cross_val_score(lr_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Linear Regression R² score:\", np.mean(lr_scores))\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(random_state=42))\n",
    "])\n",
    "\n",
    "lasso_model = Lasso(random_state=42)\n",
    "param_grid_lasso = {'lasso__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid_search_lasso = GridSearchCV(lasso_pipeline, param_grid_lasso, cv=5, scoring='r2')\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "print(\"Lasso Regression best R² score:\", grid_search_lasso.best_score_)\n",
    "print(\"Best parameters for Lasso:\", grid_search_lasso.best_params_)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "ridge_model = Ridge(random_state=42)\n",
    "param_grid_ridge = {'ridge__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid_search_ridge = GridSearchCV(ridge_pipeline, param_grid_ridge, cv=5, scoring='r2')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "print(\"Ridge Regression best R² score:\", grid_search_ridge.best_score_)\n",
    "print(\"Best parameters for Ridge:\", grid_search_ridge.best_params_)\n",
    "\n",
    "# Elastic Net Regression\n",
    "elastic_net_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elastic_net', SGDRegressor(loss='huber', penalty='elasticnet', random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "elastic_net_model = SGDRegressor(loss='huber', penalty='elasticnet', random_state=42)\n",
    "param_grid_elastic_net = {\n",
    "    'elastic_net__alpha': [0.001, 0.01, 0.1, 1],\n",
    "    'elastic_net__l1_ratio': [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "grid_search_elastic_net = GridSearchCV(elastic_net_pipeline, param_grid_elastic_net, cv=5, scoring='r2')\n",
    "grid_search_elastic_net.fit(X_train, y_train)\n",
    "print(\"Elastic Net Regression best R² score:\", grid_search_elastic_net.best_score_)\n",
    "print(\"Best parameters for Elastic Net:\", grid_search_elastic_net.best_params_)\n",
    "\n",
    "## Predicciones para el Conjunto de Prueba ##\n",
    "predictions_knn = knn_pipeline.predict(X_test)\n",
    "predictions_dt = dt_model.predict(X_test)\n",
    "\n",
    "## Generación de Archivos de Sumisión ##\n",
    "submission_knn = pd.DataFrame({'ID': df_test_processed.index, 'RENTALS': predictions_knn})\n",
    "submission_dt = pd.DataFrame({'ID': df_test_processed.index, 'RENTALS': predictions_dt})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be1512ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reevaluado KNN R² score: 0.6741348186011191\n",
      "Reevaluado Decision Tree R² score: 0.605845117113854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Asume que knn_pipeline y dt_model ya están definidos con los mejores hiperparámetros encontrados\n",
    "\n",
    "# Reevaluación de KNN\n",
    "knn_scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Reevaluado KNN R² score:\", np.mean(knn_scores))\n",
    "\n",
    "# Reevaluación de Decision Tree\n",
    "dt_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Reevaluado Decision Tree R² score:\", np.mean(dt_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25f4583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación Cruzada Anidada - Score R² para KNN: 0.7278227141774567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Continúa con la definición del pipeline y el proceso de validación cruzada anidada\n",
    "knn_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Validación cruzada externa\n",
    "external_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista para almacenar los scores de cada iteración de validación cruzada externa\n",
    "nested_scores_knn = []\n",
    "\n",
    "for train_index, test_index in external_cv.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "\n",
    "# Definición del espacio de hiperparámetros para GridSearchCV con KNN\n",
    "param_grid_knn = {\n",
    "    'knn__n_neighbors': [3, 5, 8],  # Prueba con 3, 5, y 8 vecinos\n",
    "    'knn__weights': ['uniform', 'distance'],  # Prueba ambos tipos de ponderación\n",
    "    'knn__metric': ['euclidean', 'manhattan']  # Prueba con métricas euclidiana y de manhattan\n",
    "}\n",
    "\n",
    "# Ahora puedes continuar con la configuración previa de GridSearchCV y el ciclo de validación cruzada anidada\n",
    "\n",
    "    \n",
    "# Búsqueda de hiperparámetros dentro de la validación cruzada interna\n",
    "grid_search = GridSearchCV(knn_pipeline, param_grid_knn, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    " # Evaluación en el conjunto de prueba de la iteración externa\n",
    "best_model = grid_search.best_estimator_\n",
    "nested_score = best_model.score(X_test_fold, y_test_fold)\n",
    "nested_scores_knn.append(nested_score)\n",
    "\n",
    "# Resultado final de la validación cruzada anidada para KNN\n",
    "print(\"Validación Cruzada Anidada - Score R² para KNN:\", np.mean(nested_scores_knn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41f90087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación Cruzada Anidada - Score R² para Decision Tree: 0.5393699262686694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición del modelo de Decision Tree\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# Espacio de hiperparámetros para GridSearchCV con Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Lista para almacenar los scores de cada iteración de validación cruzada externa para Decision Tree\n",
    "nested_scores_dt = []\n",
    "\n",
    "for train_index, test_index in external_cv.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Búsqueda de hiperparámetros dentro de la validación cruzada interna para Decision Tree\n",
    "    grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5, scoring='r2')\n",
    "    grid_search_dt.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Evaluación en el conjunto de prueba de la iteración externa para Decision Tree\n",
    "    best_model_dt = grid_search_dt.best_estimator_\n",
    "    nested_score_dt = best_model_dt.score(X_test_fold, y_test_fold)\n",
    "    nested_scores_dt.append(nested_score_dt)\n",
    "\n",
    "# Resultado final de la validación cruzada anidada para Decision Tree\n",
    "print(\"Validación Cruzada Anidada - Score R² para Decision Tree:\", np.mean(nested_scores_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d47e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para KNN: {'knn__metric': 'manhattan', 'knn__n_neighbors': 8, 'knn__weights': 'distance'}\n",
      "Mejor score R² para KNN: 0.6759888564703906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Definición del pipeline de KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Espacio de hiperparámetros para RandomizedSearchCV\n",
    "param_distributions_knn = {\n",
    "    'knn__n_neighbors': randint(1, 30),  # Explora un rango más amplio para el número de vecinos\n",
    "    'knn__metric': ['euclidean', 'manhattan'],  # Métricas de distancia\n",
    "    'knn__weights': ['uniform', 'distance']  # Tipo de pesos\n",
    "}\n",
    "\n",
    "# Configuración de RandomizedSearchCV\n",
    "random_search_knn = RandomizedSearchCV(knn_pipeline, param_distributions=param_distributions_knn, n_iter=100, cv=5, scoring='r2', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ejecución de la búsqueda\n",
    "random_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Mejores parámetros y score R²\n",
    "print(\"Mejores parámetros para KNN:\", random_search_knn.best_params_)\n",
    "print(\"Mejor score R² para KNN:\", random_search_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75550a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Decision Tree: {'ccp_alpha': 0.1, 'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
      "Mejor score R² para Decision Tree: 0.605845117113854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Espacio de hiperparámetros para RandomizedSearchCV con Decision Tree\n",
    "param_distributions_dt = {\n",
    "    'max_depth': randint(3, 20),  # Profundidad máxima del árbol\n",
    "    'min_samples_split': randint(2, 20),  # Número mínimo de muestras requeridas para dividir un nodo\n",
    "    'min_samples_leaf': randint(1, 20),  # Número mínimo de muestras requeridas en un nodo hoja\n",
    "    'ccp_alpha': [0.0, 0.01, 0.1, 1.0]  # Valores de ccp_alpha para la poda de costo-complejidad\n",
    "}\n",
    "\n",
    "# Configuración de RandomizedSearchCV para Decision Tree\n",
    "random_search_dt = RandomizedSearchCV(DecisionTreeRegressor(random_state=42), param_distributions=param_distributions_dt, n_iter=100, cv=5, scoring='r2', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ejecución de la búsqueda\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Mejores parámetros y score R²\n",
    "print(\"Mejores parámetros para Decision Tree:\", random_search_dt.best_params_)\n",
    "print(\"Mejor score R² para Decision Tree:\", random_search_dt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f05bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
