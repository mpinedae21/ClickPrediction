{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a81393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Marcio Pineda\\AppData\\Local\\Temp\\ipykernel_30188\\3099177956.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cleaned.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio del modelo limpio: 746.8661522231882\n",
      "Casos de valores at√≠picos:\n",
      "      entry_id     Publisher Name          Keyword Match Type  \\\n",
      "5      mkt_007        Google - US       air france      Broad   \n",
      "184   mkt_1082  Overture - Global    france travel   Advanced   \n",
      "209   mkt_1105      Overture - US   airline ticket   Standard   \n",
      "475   mkt_1349    Google - Global     [air france]      Exact   \n",
      "592   mkt_1459        Google - US   air france com      Broad   \n",
      "676   mkt_1536         Yahoo - US        airfrance   Advanced   \n",
      "685   mkt_1544        Google - US       air france      Broad   \n",
      "982   mkt_1818      Overture - US        airfrance   Standard   \n",
      "983   mkt_1819      Overture - US    europe travel   Standard   \n",
      "1314  mkt_2127        Google - US  flight to paris      Broad   \n",
      "1453  mkt_2255         Yahoo - US        airfrance   Advanced   \n",
      "1685  mkt_2468       MSN - Global       air france      Broad   \n",
      "2084  mkt_2839        Google - US        airfrance      Broad   \n",
      "2348  mkt_3088    Google - Global       air france      Broad   \n",
      "2451  mkt_3185         Yahoo - US    airfrance.com   Advanced   \n",
      "2896  mkt_3599           MSN - US       air france      Broad   \n",
      "2979  mkt_3675  Overture - Global  flight to paris   Advanced   \n",
      "3155  mkt_3839  Overture - Global   airline ticket   Standard   \n",
      "3984   mkt_560      Overture - US          airfare   Standard   \n",
      "4230   mkt_814        Google - US     [air france]      Exact   \n",
      "\n",
      "                                    Campaign       Keyword Group  \\\n",
      "5                         Air France Branded    Air France Brand   \n",
      "184                               Unassigned          Unassigned   \n",
      "209                               Unassigned          Unassigned   \n",
      "475   Air France Brand & French Destinations    Air France Brand   \n",
      "592                       Air France Branded  Air France Website   \n",
      "676                       Air France Branded  Air France Website   \n",
      "685                       Air France Branded  Air France Website   \n",
      "982                               Unassigned          Unassigned   \n",
      "983                               Unassigned          Unassigned   \n",
      "1314                      Air France Branded  Air France Website   \n",
      "1453                      Air France Branded    Air France Brand   \n",
      "1685  Air France Brand & French Destinations    Air France Brand   \n",
      "2084                      Air France Branded    Air France Brand   \n",
      "2348  Air France Brand & French Destinations    Air France Brand   \n",
      "2451                      Air France Branded  Air France Website   \n",
      "2896  Air France Brand & French Destinations    Air France Brand   \n",
      "2979                              Unassigned          Unassigned   \n",
      "3155                              Unassigned          Unassigned   \n",
      "3984                              Unassigned          Unassigned   \n",
      "4230                      Air France Branded    Air France Brand   \n",
      "\n",
      "            Category               Bid Strategy       Status  \\\n",
      "5      uncategorized                        NaN         Live   \n",
      "184           france                        NaN         Sent   \n",
      "209          airline  Position 1-4 Bid Strategy  Unavailable   \n",
      "475    uncategorized                        NaN  Unavailable   \n",
      "592    uncategorized  Postiion 1-4 Bid Strategy         Live   \n",
      "676    uncategorized                        NaN         Live   \n",
      "685    uncategorized                        NaN       Paused   \n",
      "982        airfrance                        NaN       Paused   \n",
      "983          europe2  Position 1-4 Bid Strategy       Paused   \n",
      "1314   uncategorized  Postiion 1-4 Bid Strategy       Paused   \n",
      "1453   uncategorized                        NaN         Live   \n",
      "1685   uncategorized  Position 1-4 Bid Strategy  Deactivated   \n",
      "2084   uncategorized                        NaN         Live   \n",
      "2348   uncategorized                        NaN  Unavailable   \n",
      "2451   uncategorized                        NaN         Live   \n",
      "2896   uncategorized                        NaN         Live   \n",
      "2979           paris        Position 1-2 Target         Sent   \n",
      "3155         airline                        NaN  Unavailable   \n",
      "3984  airfaregeneral  Position 1-4 Bid Strategy  Unavailable   \n",
      "4230   uncategorized                        NaN         Live   \n",
      "\n",
      "      Search Engine Bid  ...  Topic_3  Topic_4  Topic_5  Topic_6 Topic_7  \\\n",
      "5                 27.50  ...    False     True    False    False   False   \n",
      "184                8.75  ...    False    False     True    False   False   \n",
      "209                7.50  ...    False     True    False    False   False   \n",
      "475                5.00  ...    False     True    False    False   False   \n",
      "592               15.00  ...    False    False    False     True   False   \n",
      "676                7.50  ...    False    False    False    False   False   \n",
      "685               15.00  ...    False     True    False    False   False   \n",
      "982                7.50  ...    False    False    False    False   False   \n",
      "983                6.26  ...    False    False     True    False   False   \n",
      "1314              12.50  ...    False     True    False    False   False   \n",
      "1453               6.25  ...    False    False    False    False   False   \n",
      "1685               0.00  ...    False     True    False    False   False   \n",
      "2084              27.50  ...    False    False    False    False   False   \n",
      "2348               5.00  ...    False     True    False    False   False   \n",
      "2451               7.50  ...    False    False    False     True   False   \n",
      "2896               0.00  ...    False     True    False    False   False   \n",
      "2979               1.25  ...    False     True    False    False   False   \n",
      "3155               7.50  ...    False     True    False    False   False   \n",
      "3984               7.50  ...     True    False    False    False   False   \n",
      "4230              27.50  ...    False     True    False    False   False   \n",
      "\n",
      "      Topic_8  Topic_9  Keyword Cluster               Interaction  \\\n",
      "5       False    False                7          air france_Broad   \n",
      "184     False    False                5    france travel_Advanced   \n",
      "209     False    False                1   airline ticket_Standard   \n",
      "475     False    False                7        [air france]_Exact   \n",
      "592     False    False                7      air france com_Broad   \n",
      "676     False    False                4        airfrance_Advanced   \n",
      "685     False    False                7          air france_Broad   \n",
      "982     False    False                4        airfrance_Standard   \n",
      "983     False    False                5    europe travel_Standard   \n",
      "1314    False    False                2     flight to paris_Broad   \n",
      "1453    False    False                4        airfrance_Advanced   \n",
      "1685    False    False                7          air france_Broad   \n",
      "2084    False    False                4           airfrance_Broad   \n",
      "2348    False    False                7          air france_Broad   \n",
      "2451    False    False                4    airfrance.com_Advanced   \n",
      "2896    False    False                7          air france_Broad   \n",
      "2979    False    False                2  flight to paris_Advanced   \n",
      "3155    False    False                1   airline ticket_Standard   \n",
      "3984    False    False                3          airfare_Standard   \n",
      "4230    False    False                7        [air france]_Exact   \n",
      "\n",
      "      Impressions Category  \n",
      "5                        4  \n",
      "184                      4  \n",
      "209                      4  \n",
      "475                      4  \n",
      "592                      4  \n",
      "676                      4  \n",
      "685                      4  \n",
      "982                      4  \n",
      "983                      4  \n",
      "1314                     4  \n",
      "1453                     4  \n",
      "1685                     4  \n",
      "2084                     4  \n",
      "2348                     4  \n",
      "2451                     4  \n",
      "2896                     4  \n",
      "2979                     4  \n",
      "3155                     4  \n",
      "3984                     4  \n",
      "4230                     4  \n",
      "\n",
      "[20 rows x 27 columns]\n",
      "Resultados de ANOVA: F_onewayResult(statistic=1.9627716431366737, pvalue=0.14094885350434347)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Descargas necesarias para NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Definir funciones de preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Tokenizaci√≥n\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Eliminaci√≥n de stopwords y puntuaci√≥n\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english') and token not in string.punctuation]\n",
    "    # Lematizaci√≥n\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocesamiento de la columna 'Keyword'\n",
    "df_train['Preprocessed Keyword'] = df_train['Keyword'].apply(preprocess_text)\n",
    "\n",
    "# Vectorizaci√≥n TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=600)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_train['Preprocessed Keyword'])\n",
    "\n",
    "# Modelado LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda_model.fit(tfidf_matrix)\n",
    "\n",
    "# Asignar a cada muestra el t√≥pico m√°s probable de LDA\n",
    "df_train['Topic'] = lda_model.transform(tfidf_matrix).argmax(axis=1)\n",
    "\n",
    "# Convertir la columna 'Topic' en variables dummy\n",
    "df_train = pd.get_dummies(df_train, columns=['Topic'], drop_first=True)\n",
    "\n",
    "# Definir kmeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "# Ajustar el modelo KMeans\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "def preprocess_df_general(df, kmeans):\n",
    "    # Limpiar columnas num√©ricas, excepto 'Clicks'\n",
    "    numeric_cols = ['Search Engine Bid', 'Avg. Pos.', 'Avg. Cost per Click', 'Impressions']\n",
    "    for col in numeric_cols:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = pd.to_numeric(df[col].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "    df['Impressions'].fillna(df['Impressions'].median(), inplace=True)\n",
    "\n",
    "    # Procesamiento que aplica tanto al conjunto de entrenamiento como al de prueba\n",
    "    keywords_tfidf = tfidf_vectorizer.transform(df['Keyword'].str.lower())\n",
    "    keyword_clusters = kmeans.predict(keywords_tfidf)\n",
    "    df['Keyword Cluster'] = keyword_clusters\n",
    "    df['Interaction'] = df['Keyword'].astype(str) + '_' + df['Match Type'].astype(str)\n",
    "    bin_edges = [0, 100, 1000, 10000, np.inf]\n",
    "    bin_labels = [1, 2, 3, 4]\n",
    "    df['Impressions Category'] = pd.cut(df['Impressions'], bins=bin_edges, labels=bin_labels, right=False).cat.add_categories([0]).fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_df_train(df, kmeans):\n",
    "    df = preprocess_df_general(df, kmeans)\n",
    "    # Limpiar y convertir 'Clicks' a num√©rico solo para el conjunto de entrenamiento\n",
    "    df['Clicks'] = pd.to_numeric(df['Clicks'].str.replace(',', ''), errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "df_train_cleaned = preprocess_df_train(df_train.copy(), kmeans)\n",
    "df_test_cleaned = preprocess_df_general(df_test.copy(), kmeans)\n",
    "\n",
    "selected_features = ['Search Engine Bid', 'Impressions Category', 'Avg. Pos.', 'Keyword Cluster']\n",
    "X_train_cleaned = df_train_cleaned[selected_features]\n",
    "y_train_cleaned = df_train_cleaned['Clicks'].astype(float)\n",
    "X_train_cleaned.fillna(0, inplace=True)\n",
    "\n",
    "# Ajustar el modelo de regresi√≥n lineal\n",
    "model_cleaned = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Realizar cross-validation con el modelo de regresi√≥n lineal\n",
    "cv_scores_cleaned = cross_val_score(model_cleaned, X_train_cleaned, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_cleaned = np.sqrt(-cv_scores_cleaned)\n",
    "cv_rmse_cleaned_mean = cv_rmse_cleaned.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo limpio:\", cv_rmse_cleaned_mean)\n",
    "\n",
    "# An√°lisis de Valores At√≠picos\n",
    "# Investigar los casos de valores at√≠picos para determinar su naturaleza\n",
    "outliers = df_train_cleaned[(np.abs(df_train_cleaned['Clicks'] - df_train_cleaned['Clicks'].mean()) > (3 * df_train_cleaned['Clicks'].std()))]\n",
    "print(\"Casos de valores at√≠picos:\")\n",
    "print(outliers)\n",
    "\n",
    "# Evaluaci√≥n Estad√≠stica\n",
    "# Prueba de ANOVA para determinar si las diferencias en los 'Clicks' entre los t√≥picos son significativas\n",
    "anova_result = f_oneway(\n",
    "    df_train_cleaned[df_train_cleaned['Topic_1'] == 1]['Clicks'],\n",
    "    df_train_cleaned[df_train_cleaned['Topic_2'] == 1]['Clicks'],\n",
    "    df_train_cleaned[df_train_cleaned['Topic_3'] == 1]['Clicks']\n",
    ")\n",
    "\n",
    "print(\"Resultados de ANOVA:\", anova_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1ef9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio del modelo RandomForestRegressor: 746.8661522231882\n",
      "RMSE promedio del modelo GradientBoostingRegressor: 856.1206204153044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelos RandomForestRegressor y GradientBoostingRegressor\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Variables predictoras y variable objetivo\n",
    "X_train = df_train_cleaned[selected_features]\n",
    "y_train = df_train_cleaned['Clicks']\n",
    "\n",
    "# Validaci√≥n cruzada con RandomForestRegressor\n",
    "cv_scores_rf = cross_val_score(model_rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_rf = np.sqrt(-cv_scores_rf)\n",
    "cv_rmse_rf_mean = cv_rmse_rf.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo RandomForestRegressor:\", cv_rmse_rf_mean)\n",
    "\n",
    "# Validaci√≥n cruzada con GradientBoostingRegressor\n",
    "cv_scores_gb = cross_val_score(model_gb, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_gb = np.sqrt(-cv_scores_gb)\n",
    "cv_rmse_gb_mean = cv_rmse_gb.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo GradientBoostingRegressor:\", cv_rmse_gb_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa50ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Definir el espacio de b√∫squeda de hiperpar√°metros para RandomForestRegressor\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Inicializar el modelo RandomForestRegressor\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Realizar la b√∫squeda de cuadr√≠cula con validaci√≥n cruzada para RandomForestRegressor\n",
    "grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Mejores hiperpar√°metros encontrados para RandomForestRegressor\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a710acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
