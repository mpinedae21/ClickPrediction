{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac981872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Publisher Name</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Keyword Group</th>\n",
       "      <th>Category</th>\n",
       "      <th>Bid Strategy</th>\n",
       "      <th>Status</th>\n",
       "      <th>Search Engine Bid</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>...</th>\n",
       "      <th>washington</th>\n",
       "      <th>web</th>\n",
       "      <th>webpage</th>\n",
       "      <th>website</th>\n",
       "      <th>welcome</th>\n",
       "      <th>xpress</th>\n",
       "      <th>yaoundé</th>\n",
       "      <th>york</th>\n",
       "      <th>zagreb</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mkt_001</td>\n",
       "      <td>Google - Global</td>\n",
       "      <td>Broad</td>\n",
       "      <td>Air France Global Campaign</td>\n",
       "      <td>Nice</td>\n",
       "      <td>nice</td>\n",
       "      <td>Position 1- 3</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.535048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkt_002</td>\n",
       "      <td>Yahoo - US</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>Western Europe Destinations</td>\n",
       "      <td>Munich</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paused</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.097339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mkt_003</td>\n",
       "      <td>Overture - Global</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>paris</td>\n",
       "      <td>Position 1-2 Target</td>\n",
       "      <td>Sent</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.067727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mkt_005</td>\n",
       "      <td>Yahoo - US</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>Geo Targeted Los Angeles</td>\n",
       "      <td>Discount International Los Angeles</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paused</td>\n",
       "      <td>6.25</td>\n",
       "      <td>4.223870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mkt_006</td>\n",
       "      <td>Google - US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Google_Yearlong 2006</td>\n",
       "      <td>Google|marrakech</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.842522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  entry_id     Publisher Name Match Type                     Campaign  \\\n",
       "0  mkt_001    Google - Global      Broad   Air France Global Campaign   \n",
       "1  mkt_002         Yahoo - US   Advanced  Western Europe Destinations   \n",
       "2  mkt_003  Overture - Global   Advanced                   Unassigned   \n",
       "3  mkt_005         Yahoo - US   Advanced     Geo Targeted Los Angeles   \n",
       "4  mkt_006        Google - US        NaN         Google_Yearlong 2006   \n",
       "\n",
       "                        Keyword Group       Category         Bid Strategy  \\\n",
       "0                                Nice           nice        Position 1- 3   \n",
       "1                              Munich  uncategorized                  NaN   \n",
       "2                          Unassigned          paris  Position 1-2 Target   \n",
       "3  Discount International Los Angeles  uncategorized                  NaN   \n",
       "4                    Google|marrakech  uncategorized                  NaN   \n",
       "\n",
       "        Status  Search Engine Bid  Impressions  ...  washington  web webpage  \\\n",
       "0  Unavailable               1.25     5.535048  ...         0.0  0.0     0.0   \n",
       "1       Paused               6.25     3.097339  ...         0.0  0.0     0.0   \n",
       "2         Sent               0.45     7.067727  ...         0.0  0.0     0.0   \n",
       "3       Paused               6.25     4.223870  ...         0.0  0.0     0.0   \n",
       "4  Unavailable               7.50     2.842522  ...         0.0  0.0     0.0   \n",
       "\n",
       "   website  welcome  xpress  yaoundé  york  zagreb  zurich  \n",
       "0      0.0      0.0     0.0      0.0   0.0     0.0     0.0  \n",
       "1      0.0      0.0     0.0      0.0   0.0     0.0     0.0  \n",
       "2      0.0      0.0     0.0      0.0   0.0     0.0     0.0  \n",
       "3      0.0      0.0     0.0      0.0   0.0     0.0     0.0  \n",
       "4      0.0      0.0     0.0      0.0   0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "\n",
    "df_train['Keyword'] = df_train['Keyword'].str.lower()  # Convertir a minúsculas\n",
    "all_keywords = df_train['Keyword']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=600)\n",
    "df_train_tfidf = tfidf_vectorizer.fit_transform(all_keywords)\n",
    "df_train_tfidf_df = pd.DataFrame(df_train_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=df_train.index)\n",
    "\n",
    "# Concatenar TF-IDF con los conjuntos de datos originales\n",
    "df_train = pd.concat([df_train.drop(columns=['Keyword']), df_train_tfidf_df], axis=1)\n",
    "\n",
    "# Función para limpiar columnas numéricas\n",
    "def clean_numeric_column(column):\n",
    "    # Elimina comas, signos de dólar, y espacios en blanco antes de convertir\n",
    "    column_as_str = column.astype(str).str.replace(',', '').str.replace('$', '').str.strip()\n",
    "    return pd.to_numeric(column_as_str, errors='coerce')\n",
    "   \n",
    "\n",
    "# Limpieza de columnas numéricas\n",
    "columns_to_clean = ['Search Engine Bid', 'Impressions', 'Avg. Cost per Click', 'Avg. Pos.']\n",
    "for column in columns_to_clean:\n",
    "    df_train[column] = clean_numeric_column(df_train[column])\n",
    "\n",
    "# Reemplazar ceros en 'Impressions' para la transformación Box-Cox\n",
    "min_value = df_train[df_train['Impressions'] > 0]['Impressions'].min()\n",
    "df_train['Impressions'] = df_train['Impressions'].replace(0, min_value)\n",
    "fitted_lambda = stats.boxcox(df_train['Impressions'])[1]\n",
    "df_train['Impressions'] = stats.boxcox(df_train['Impressions'], lmbda=fitted_lambda)\n",
    "\n",
    "# Visualizar los primeros registros del conjunto de entrenamiento\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1acdbc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '9,391'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     43\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 44\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:493\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    483\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    484\u001b[0m         (\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[0;32m    497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    498\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:572\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    514\u001b[0m     {\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m ):\n\u001b[0;32m    525\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 572\u001b[0m         mean_squared_error(\n\u001b[0;32m    573\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m     )\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[1;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    498\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:103\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\Documents\\Python\\Lib\\site-packages\\pandas\\core\\series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    916\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m--> 917\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    919\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '9,391'"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que 'Clicks' también esté limpia si va a ser utilizada como tu variable objetivo\n",
    "df_train['Clicks'] = clean_numeric_column(df_train['Clicks'])\n",
    "\n",
    "# Dividir los datos en características (X) y objetivo (y)\n",
    "# Asegúrate de no incluir columnas no deseadas en X\n",
    "X = df_train.drop(columns=['Clicks', 'entry_id'], errors='ignore')\n",
    "\n",
    "X = pd.concat([X, df_train_tfidf_df], axis=1)  # Añadir características TF-IDF\n",
    "y = df_train['Clicks']\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Asume que has identificado las columnas para One-Hot Encoding y Target Encoding\n",
    "one_hot_cols = ['Match Type', 'Bid Strategy', 'Status']\n",
    "target_encode_cols = ['Campaign', 'Category', 'Publisher Name', 'Keyword Group']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', SklearnOneHotEncoder(), one_hot_cols),\n",
    "        ('target_encode', ce.TargetEncoder(), target_encode_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Mantener el resto de las columnas sin cambios\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447856e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m one_hot_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatch Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBid Strategy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m one_hot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(cols\u001b[38;5;241m=\u001b[39mone_hot_cols, use_cat_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m X_train_one_hot \u001b[38;5;241m=\u001b[39m one_hot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(X_train[one_hot_cols])\n\u001b[0;32m      9\u001b[0m X_val_one_hot \u001b[38;5;241m=\u001b[39m one_hot_encoder\u001b[38;5;241m.\u001b[39mtransform(X_val[one_hot_cols])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Aplicar Target Encoding a variables con un número moderado de categorías\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Asegúrate de que todas las columnas que se van a procesar con One-Hot Encoding o Target Encoding existen\n",
    "one_hot_cols = [col for col in ['Match Type', 'Bid Strategy', 'Status'] if col in X.columns]\n",
    "target_encode_cols = [col for col in ['Campaign', 'Category', 'Publisher Name', 'Keyword Group'] if col in X.columns]\n",
    "\n",
    "# Aplicar One-Hot Encoding a variables con pocas categorías\n",
    "one_hot_cols = ['Match Type', 'Bid Strategy', 'Status']\n",
    "one_hot_encoder = OneHotEncoder(cols=one_hot_cols, use_cat_names=True)\n",
    "X_train_one_hot = one_hot_encoder.fit_transform(X_train[one_hot_cols])\n",
    "X_val_one_hot = one_hot_encoder.transform(X_val[one_hot_cols])\n",
    "\n",
    "# Aplicar Target Encoding a variables con un número moderado de categorías\n",
    "target_encode_cols = ['Campaign', 'Category', 'Publisher Name', 'Keyword Group']\n",
    "target_encoder = TargetEncoder(cols=target_encode_cols)\n",
    "X_train_target_encoded = target_encoder.fit_transform(X_train[target_encode_cols], y_train)\n",
    "X_val_target_encoded = target_encoder.transform(X_val[target_encode_cols])\n",
    "\n",
    "# Unir las transformaciones con el resto de datos (excluyendo las columnas originales que ya han sido codificadas)\n",
    "X_train_processed = X_train.drop(one_hot_cols + target_encode_cols, axis=1).join(X_train_one_hot).join(X_train_target_encoded)\n",
    "X_val_processed = X_val.drop(one_hot_cols + target_encode_cols, axis=1).join(X_val_one_hot).join(X_val_target_encoded)\n",
    "\n",
    "# Ahora X_train_processed y X_val_processed están listos para ser usados en el modelado\n",
    "\n",
    "print(\"Dimensiones de X_train procesado:\", X_train_processed.shape)\n",
    "print(\"Dimensiones de X_val procesado:\", X_val_processed.shape)\n",
    "\n",
    "print(\"Primeras filas de X_train procesado:\\n\", X_train_processed.head())\n",
    "print(\"Primeras filas de X_val procesado:\\n\", X_val_processed.head())\n",
    "\n",
    "print(\"Resumen estadístico de X_train procesado:\\n\", X_train_processed.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b002ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
