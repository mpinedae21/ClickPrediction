{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286903d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Marcio\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Marcio Pineda\\AppData\\Local\\Temp\\ipykernel_21272\\314942815.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cleaned.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio del modelo limpio con transformaciones logarítmicas y características polinómicas: 674.388945596839\n",
      "Casos de valores atípicos:\n",
      "      entry_id     Publisher Name          Keyword Match Type  \\\n",
      "5      mkt_007        Google - US       air france      Broad   \n",
      "184   mkt_1082  Overture - Global    france travel   Advanced   \n",
      "209   mkt_1105      Overture - US   airline ticket   Standard   \n",
      "475   mkt_1349    Google - Global     [air france]      Exact   \n",
      "592   mkt_1459        Google - US   air france com      Broad   \n",
      "676   mkt_1536         Yahoo - US        airfrance   Advanced   \n",
      "685   mkt_1544        Google - US       air france      Broad   \n",
      "982   mkt_1818      Overture - US        airfrance   Standard   \n",
      "983   mkt_1819      Overture - US    europe travel   Standard   \n",
      "1314  mkt_2127        Google - US  flight to paris      Broad   \n",
      "1453  mkt_2255         Yahoo - US        airfrance   Advanced   \n",
      "1685  mkt_2468       MSN - Global       air france      Broad   \n",
      "2084  mkt_2839        Google - US        airfrance      Broad   \n",
      "2348  mkt_3088    Google - Global       air france      Broad   \n",
      "2451  mkt_3185         Yahoo - US    airfrance.com   Advanced   \n",
      "2896  mkt_3599           MSN - US       air france      Broad   \n",
      "2979  mkt_3675  Overture - Global  flight to paris   Advanced   \n",
      "3155  mkt_3839  Overture - Global   airline ticket   Standard   \n",
      "3984   mkt_560      Overture - US          airfare   Standard   \n",
      "4230   mkt_814        Google - US     [air france]      Exact   \n",
      "\n",
      "                                    Campaign       Keyword Group  \\\n",
      "5                         Air France Branded    Air France Brand   \n",
      "184                               Unassigned          Unassigned   \n",
      "209                               Unassigned          Unassigned   \n",
      "475   Air France Brand & French Destinations    Air France Brand   \n",
      "592                       Air France Branded  Air France Website   \n",
      "676                       Air France Branded  Air France Website   \n",
      "685                       Air France Branded  Air France Website   \n",
      "982                               Unassigned          Unassigned   \n",
      "983                               Unassigned          Unassigned   \n",
      "1314                      Air France Branded  Air France Website   \n",
      "1453                      Air France Branded    Air France Brand   \n",
      "1685  Air France Brand & French Destinations    Air France Brand   \n",
      "2084                      Air France Branded    Air France Brand   \n",
      "2348  Air France Brand & French Destinations    Air France Brand   \n",
      "2451                      Air France Branded  Air France Website   \n",
      "2896  Air France Brand & French Destinations    Air France Brand   \n",
      "2979                              Unassigned          Unassigned   \n",
      "3155                              Unassigned          Unassigned   \n",
      "3984                              Unassigned          Unassigned   \n",
      "4230                      Air France Branded    Air France Brand   \n",
      "\n",
      "            Category               Bid Strategy       Status  \\\n",
      "5      uncategorized                        NaN         Live   \n",
      "184           france                        NaN         Sent   \n",
      "209          airline  Position 1-4 Bid Strategy  Unavailable   \n",
      "475    uncategorized                        NaN  Unavailable   \n",
      "592    uncategorized  Postiion 1-4 Bid Strategy         Live   \n",
      "676    uncategorized                        NaN         Live   \n",
      "685    uncategorized                        NaN       Paused   \n",
      "982        airfrance                        NaN       Paused   \n",
      "983          europe2  Position 1-4 Bid Strategy       Paused   \n",
      "1314   uncategorized  Postiion 1-4 Bid Strategy       Paused   \n",
      "1453   uncategorized                        NaN         Live   \n",
      "1685   uncategorized  Position 1-4 Bid Strategy  Deactivated   \n",
      "2084   uncategorized                        NaN         Live   \n",
      "2348   uncategorized                        NaN  Unavailable   \n",
      "2451   uncategorized                        NaN         Live   \n",
      "2896   uncategorized                        NaN         Live   \n",
      "2979           paris        Position 1-2 Target         Sent   \n",
      "3155         airline                        NaN  Unavailable   \n",
      "3984  airfaregeneral  Position 1-4 Bid Strategy  Unavailable   \n",
      "4230   uncategorized                        NaN         Live   \n",
      "\n",
      "      Search Engine Bid  ...  Topic_6  Topic_7  Topic_8  Topic_9  \\\n",
      "5                 27.50  ...    False    False    False    False   \n",
      "184                8.75  ...    False    False    False    False   \n",
      "209                7.50  ...    False    False    False    False   \n",
      "475                5.00  ...    False    False    False    False   \n",
      "592               15.00  ...     True    False    False    False   \n",
      "676                7.50  ...    False    False    False    False   \n",
      "685               15.00  ...    False    False    False    False   \n",
      "982                7.50  ...    False    False    False    False   \n",
      "983                6.26  ...    False    False    False    False   \n",
      "1314              12.50  ...    False    False    False    False   \n",
      "1453               6.25  ...    False    False    False    False   \n",
      "1685               0.00  ...    False    False    False    False   \n",
      "2084              27.50  ...    False    False    False    False   \n",
      "2348               5.00  ...    False    False    False    False   \n",
      "2451               7.50  ...     True    False    False    False   \n",
      "2896               0.00  ...    False    False    False    False   \n",
      "2979               1.25  ...    False    False    False    False   \n",
      "3155               7.50  ...    False    False    False    False   \n",
      "3984               7.50  ...    False    False    False    False   \n",
      "4230              27.50  ...    False    False    False    False   \n",
      "\n",
      "     Keyword Cluster               Interaction  Impressions Category  \\\n",
      "5                  7          air france_Broad                     4   \n",
      "184                5    france travel_Advanced                     4   \n",
      "209                1   airline ticket_Standard                     4   \n",
      "475                7        [air france]_Exact                     4   \n",
      "592                7      air france com_Broad                     4   \n",
      "676                4        airfrance_Advanced                     4   \n",
      "685                7          air france_Broad                     4   \n",
      "982                4        airfrance_Standard                     4   \n",
      "983                5    europe travel_Standard                     4   \n",
      "1314               2     flight to paris_Broad                     4   \n",
      "1453               4        airfrance_Advanced                     4   \n",
      "1685               7          air france_Broad                     4   \n",
      "2084               4           airfrance_Broad                     4   \n",
      "2348               7          air france_Broad                     4   \n",
      "2451               4    airfrance.com_Advanced                     4   \n",
      "2896               7          air france_Broad                     4   \n",
      "2979               2  flight to paris_Advanced                     4   \n",
      "3155               1   airline ticket_Standard                     4   \n",
      "3984               3          airfare_Standard                     4   \n",
      "4230               7        [air france]_Exact                     4   \n",
      "\n",
      "      Log_Impressions  Search_Engine_Bid_Squared    Impressions_Cubed  \n",
      "5           12.862237                   756.2500    57278552103130176  \n",
      "184         15.936863                    76.5625  8748713973358223279  \n",
      "209         15.317928                    56.2500 -1561406681880871424  \n",
      "475         10.692490                    25.0000       85317653840167  \n",
      "592          9.626877                   225.0000        3488294594296  \n",
      "676         11.995790                    56.2500     4257041621743000  \n",
      "685         10.492662                   225.0000       46846771425649  \n",
      "982         12.125334                    56.2500     6278996542983256  \n",
      "983         15.234320                    39.1876 -3229497452170197091  \n",
      "1314        11.687148                   156.2500     1686476316106791  \n",
      "1453        10.080503                    39.0625       13603993550848  \n",
      "1685        10.685630                     0.0000       83579556003048  \n",
      "2084        11.274859                   756.2500      489564714817144  \n",
      "2348        10.537972                    25.0000       53667955648000  \n",
      "2451        10.124028                    56.2500       15501576412504  \n",
      "2896        10.572675                     0.0000       59556592508608  \n",
      "2979        12.206228                     1.5625     8003600540027000  \n",
      "3155        15.202977                    56.2500  8885103722619079921  \n",
      "3984        14.165598                    56.2500  2858390942454559000  \n",
      "4230        12.146376                   756.2500     6688133502901929  \n",
      "\n",
      "[20 rows x 30 columns]\n",
      "Resultados de ANOVA: F_onewayResult(statistic=1.9627716431366737, pvalue=0.14094885350434347)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Descargas necesarias para NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Cargar los conjuntos de datos\n",
    "ruta_train = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/traincase.csv'\n",
    "ruta_test = 'C:/Users/Marcio Pineda/Documents/Archivos Python/datasets/testcase.csv'\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "# Definir funciones de preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Eliminación de stopwords y puntuación\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english') and token not in string.punctuation]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocesamiento de la columna 'Keyword'\n",
    "df_train['Preprocessed Keyword'] = df_train['Keyword'].apply(preprocess_text)\n",
    "\n",
    "# Vectorización TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=600)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_train['Preprocessed Keyword'])\n",
    "\n",
    "# Modelado LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda_model.fit(tfidf_matrix)\n",
    "\n",
    "# Asignar a cada muestra el tópico más probable de LDA\n",
    "df_train['Topic'] = lda_model.transform(tfidf_matrix).argmax(axis=1)\n",
    "\n",
    "# Convertir la columna 'Topic' en variables dummy\n",
    "df_train = pd.get_dummies(df_train, columns=['Topic'], drop_first=True)\n",
    "\n",
    "# Definir kmeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "# Ajustar el modelo KMeans\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "def preprocess_df_general(df, kmeans):\n",
    "    # Limpiar columnas numéricas, excepto 'Clicks'\n",
    "    numeric_cols = ['Search Engine Bid', 'Avg. Pos.', 'Avg. Cost per Click', 'Impressions']\n",
    "    for col in numeric_cols:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = pd.to_numeric(df[col].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "    df['Impressions'].fillna(df['Impressions'].median(), inplace=True)\n",
    "\n",
    "    # Procesamiento que aplica tanto al conjunto de entrenamiento como al de prueba\n",
    "    keywords_tfidf = tfidf_vectorizer.transform(df['Keyword'].str.lower())\n",
    "    keyword_clusters = kmeans.predict(keywords_tfidf)\n",
    "    df['Keyword Cluster'] = keyword_clusters\n",
    "    df['Interaction'] = df['Keyword'].astype(str) + '_' + df['Match Type'].astype(str)\n",
    "    bin_edges = [0, 100, 1000, 10000, np.inf]\n",
    "    bin_labels = [1, 2, 3, 4]\n",
    "    df['Impressions Category'] = pd.cut(df['Impressions'], bins=bin_edges, labels=bin_labels, right=False).cat.add_categories([0]).fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_df_train(df, kmeans):\n",
    "    df = preprocess_df_general(df, kmeans)\n",
    "    # Limpiar y convertir 'Clicks' a numérico solo para el conjunto de entrenamiento\n",
    "    df['Clicks'] = pd.to_numeric(df['Clicks'].str.replace(',', ''), errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "df_train_cleaned = preprocess_df_train(df_train.copy(), kmeans)\n",
    "df_test_cleaned = preprocess_df_general(df_test.copy(), kmeans)\n",
    "\n",
    "# Transformaciones logarítmicas\n",
    "df_train_cleaned['Log_Impressions'] = np.log1p(df_train_cleaned['Impressions'])\n",
    "# También puedes hacer lo mismo para df_test_cleaned si es necesario\n",
    "\n",
    "# Características polinómicas\n",
    "df_train_cleaned['Search_Engine_Bid_Squared'] = df_train_cleaned['Search Engine Bid'] ** 2\n",
    "df_train_cleaned['Impressions_Cubed'] = df_train_cleaned['Impressions'] ** 3\n",
    "# También puedes crear más características polinómicas según sea necesario\n",
    "\n",
    "# Actualizar las características seleccionadas\n",
    "selected_features = ['Search Engine Bid', 'Impressions Category', 'Avg. Pos.', 'Keyword Cluster',\n",
    "                     'Log_Impressions', 'Search_Engine_Bid_Squared', 'Impressions_Cubed']\n",
    "\n",
    "X_train_cleaned = df_train_cleaned[selected_features]\n",
    "y_train_cleaned = df_train_cleaned['Clicks'].astype(float)\n",
    "X_train_cleaned.fillna(0, inplace=True)\n",
    "\n",
    "# Ajustar el modelo de regresión lineal con las nuevas características\n",
    "model_cleaned = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Realizar cross-validation con el modelo de regresión lineal actualizado\n",
    "cv_scores_cleaned = cross_val_score(model_cleaned, X_train_cleaned, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_cleaned = np.sqrt(-cv_scores_cleaned)\n",
    "cv_rmse_cleaned_mean = cv_rmse_cleaned.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo limpio con transformaciones logarítmicas y características polinómicas:\", cv_rmse_cleaned_mean)\n",
    "\n",
    "# Análisis de Valores Atípicos\n",
    "# Investigar los casos de valores atípicos para determinar su naturaleza\n",
    "outliers = df_train_cleaned[(np.abs(df_train_cleaned['Clicks'] - df_train_cleaned['Clicks'].mean()) > (3 * df_train_cleaned['Clicks'].std()))]\n",
    "print(\"Casos de valores atípicos:\")\n",
    "print(outliers)\n",
    "\n",
    "# Evaluación Estadística\n",
    "# Prueba de ANOVA para determinar si las diferencias en los 'Clicks' entre los tópicos son significativas\n",
    "anova_result = f_oneway(\n",
    "    df_train_cleaned[df_train_cleaned['Topic_1'] == 1]['Clicks'],\n",
    "    df_train_cleaned[df_train_cleaned['Topic_2'] == 1]['Clicks'],\n",
    "    df_train_cleaned[df_train_cleaned['Topic_3'] == 1]['Clicks']\n",
    ")\n",
    "\n",
    "print(\"Resultados de ANOVA:\", anova_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be554e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio del modelo RandomForestRegressor: 679.937173429212\n",
      "RMSE promedio del modelo GradientBoostingRegressor: 859.9705740394025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelos RandomForestRegressor y GradientBoostingRegressor\n",
    "model_rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Variables predictoras y variable objetivo\n",
    "X_train = df_train_cleaned[selected_features]\n",
    "y_train = df_train_cleaned['Clicks']\n",
    "\n",
    "# Validación cruzada con RandomForestRegressor\n",
    "cv_scores_rf = cross_val_score(model_rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_rf = np.sqrt(-cv_scores_rf)\n",
    "cv_rmse_rf_mean = cv_rmse_rf.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo RandomForestRegressor:\", cv_rmse_rf_mean)\n",
    "\n",
    "# Validación cruzada con GradientBoostingRegressor\n",
    "cv_scores_gb = cross_val_score(model_gb, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_gb = np.sqrt(-cv_scores_gb)\n",
    "cv_rmse_gb_mean = cv_rmse_gb.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo GradientBoostingRegressor:\", cv_rmse_gb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define los modelos de regresión lineal\n",
    "model_lr = LinearRegression()\n",
    "model_ridge = Ridge(alpha=1.0)  # Puedes ajustar el parámetro alpha según sea necesario\n",
    "model_lasso = Lasso(alpha=1.0)  # Puedes ajustar el parámetro alpha según sea necesario\n",
    "model_elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5)  # Puedes ajustar los parámetros alpha y l1_ratio según sea necesario\n",
    "\n",
    "# Variables predictoras y variable objetivo\n",
    "X_train = df_train_cleaned[['Impressions_Cubed', 'Search_Engine_Bid_Squared', 'Log_Impressions']]\n",
    "y_train = df_train_cleaned['Clicks']\n",
    "\n",
    "# Validación cruzada con modelos de regresión lineal\n",
    "cv_scores_lr = cross_val_score(model_lr, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_lr = np.sqrt(-cv_scores_lr)\n",
    "cv_rmse_lr_mean = cv_rmse_lr.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo LinearRegression:\", cv_rmse_lr_mean)\n",
    "\n",
    "# Validación cruzada con Ridge Regression\n",
    "cv_scores_ridge = cross_val_score(model_ridge, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_ridge = np.sqrt(-cv_scores_ridge)\n",
    "cv_rmse_ridge_mean = cv_rmse_ridge.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo Ridge Regression:\", cv_rmse_ridge_mean)\n",
    "\n",
    "# Validación cruzada con Lasso Regression\n",
    "cv_scores_lasso = cross_val_score(model_lasso, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_lasso = np.sqrt(-cv_scores_lasso)\n",
    "cv_rmse_lasso_mean = cv_rmse_lasso.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo Lasso Regression:\", cv_rmse_lasso_mean)\n",
    "\n",
    "# Validación cruzada con ElasticNet Regression\n",
    "cv_scores_elasticnet = cross_val_score(model_elasticnet, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_elasticnet = np.sqrt(-cv_scores_elasticnet)\n",
    "cv_rmse_elasticnet_mean = cv_rmse_elasticnet.mean()\n",
    "\n",
    "print(\"RMSE promedio del modelo ElasticNet Regression:\", cv_rmse_elasticnet_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47777b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de entrenamiento del modelo RandomForestRegressor: 276.8687634754711\n",
      "RMSE en el conjunto de validación del modelo RandomForestRegressor: 976.9324900300777\n",
      "El modelo RandomForestRegressor podría estar sobreajustado.\n"
     ]
    }
   ],
   "source": [
    "# Variables predictoras y variable objetivo\n",
    "X_train = df_train_cleaned[selected_features_extended]\n",
    "y_train = df_train_cleaned['Clicks']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,  # Ahora usamos X_train con las características extendidas\n",
    "    y_train,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo RandomForestRegressor con todos los datos de entrenamiento\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Calcular el RMSE en el conjunto de entrenamiento\n",
    "train_predictions_rf = model_rf.predict(X_train)\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, train_predictions_rf))\n",
    "print(\"RMSE en el conjunto de entrenamiento del modelo RandomForestRegressor:\", train_rmse_rf)\n",
    "\n",
    "# Calcular el RMSE en el conjunto de validación\n",
    "valid_predictions_rf = model_rf.predict(X_valid)\n",
    "valid_rmse_rf = np.sqrt(mean_squared_error(y_valid, valid_predictions_rf))\n",
    "print(\"RMSE en el conjunto de validación del modelo RandomForestRegressor:\", valid_rmse_rf)\n",
    "\n",
    "# Verificar sobreajuste comparando el RMSE en el conjunto de entrenamiento y el conjunto de validación\n",
    "if train_rmse_rf < valid_rmse_rf:\n",
    "    print(\"El modelo RandomForestRegressor podría estar sobreajustado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942e6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "156 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "83 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "73 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Marcio Pineda\\Documents\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [              nan               nan  -762672.46383412  -733918.75189184\n",
      "  -986895.13119643               nan               nan -1001532.81569046\n",
      "               nan               nan  -671310.95315796  -921888.70198245\n",
      "  -983632.53369873  -671631.90765262               nan               nan\n",
      " -1002169.89112303               nan  -922039.9452204                nan\n",
      "  -948509.5941139   -659919.6301433   -962118.04124571  -997515.6590904\n",
      "  -750900.94357603  -923349.78863348  -983430.6254838  -1013594.79501814\n",
      "  -994149.30863829               nan               nan               nan\n",
      "               nan               nan -1013594.79501814               nan\n",
      "  -764521.55216484  -922039.9452204                nan               nan\n",
      "  -685409.37624533  -925772.88824192               nan               nan\n",
      "               nan               nan               nan               nan\n",
      " -1001532.81569046  -999963.13819507               nan               nan\n",
      "  -705547.9714564                nan               nan  -910343.76473376\n",
      "               nan -1012137.11064445               nan  -723137.74559201\n",
      "  -663569.49390858               nan  -999895.94188391               nan\n",
      "               nan  -991502.00512136               nan               nan\n",
      " -1002237.47535829  -914614.61410968               nan               nan\n",
      "               nan               nan  -983821.73367992               nan\n",
      "  -726653.86982064               nan  -986895.13119643  -954513.15824255\n",
      "               nan               nan -1014357.49810844               nan\n",
      "               nan               nan               nan  -769155.75982298\n",
      "               nan  -927732.506017                 nan -1002237.47535829\n",
      "               nan  -723199.97182756               nan  -989422.55135707\n",
      "  -926974.77462821               nan  -750900.94357603  -689475.47258899]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros de la búsqueda aleatoria: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40}\n",
      "RMSE en el conjunto de validación con el mejor modelo de la búsqueda aleatoria: 852.5829085591296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Asegúrate de aplicar las mismas transformaciones al conjunto de test\n",
    "df_test_cleaned['Log_Impressions'] = np.log1p(df_test_cleaned['Impressions'])\n",
    "df_test_cleaned['Search_Engine_Bid_Squared'] = df_test_cleaned['Search Engine Bid'] ** 2\n",
    "df_test_cleaned['Impressions_Cubed'] = df_test_cleaned['Impressions'] ** 3\n",
    "\n",
    "# Actualizar las características seleccionadas incluyendo las nuevas\n",
    "selected_features_extended = selected_features + ['Log_Impressions', 'Search_Engine_Bid_Squared', 'Impressions_Cubed']\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    df_train_cleaned[selected_features_extended],  # asegúrate de que selected_features_extended incluye las nuevas características\n",
    "    df_train_cleaned['Clicks'],\n",
    "    test_size=0.3,  # Aumentar el tamaño del conjunto de validación\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Definir el espacio de hiperparámetros para explorar\n",
    "random_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Inicializar el modelo de RandomForest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Configurar la búsqueda aleatoria con validación cruzada\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,  # Número de combinaciones de parámetros a probar\n",
    "    cv=3,  # Número de folds en la validación cruzada\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Ajustar la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ajustar la búsqueda aleatoria\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Mejores hiperparámetros encontrados\n",
    "best_random_params = rf_random.best_params_\n",
    "print(\"Mejores hiperparámetros de la búsqueda aleatoria:\", best_random_params)\n",
    "\n",
    "# Ajustar el modelo con los mejores hiperparámetros en el conjunto de entrenamiento completo\n",
    "best_model_random = rf_random.best_estimator_\n",
    "\n",
    "# Calcular el RMSE en el conjunto de validación utilizando el mejor modelo de la búsqueda aleatoria\n",
    "valid_predictions_random = best_model_random.predict(X_valid)\n",
    "valid_rmse_random = np.sqrt(mean_squared_error(y_valid, valid_predictions_random))\n",
    "\n",
    "print(\"RMSE en el conjunto de validación con el mejor modelo de la búsqueda aleatoria:\", valid_rmse_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77b6f9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de entrenamiento con el mejor modelo de la búsqueda aleatoria: 312.9735866275712\n",
      "RMSE en el conjunto de validación con el mejor modelo de la búsqueda aleatoria: 327.93438945001\n",
      "El modelo con los mejores hiperparámetros podría estar sobreajustado.\n"
     ]
    }
   ],
   "source": [
    "# Ajustar el modelo con los mejores hiperparámetros en el conjunto de entrenamiento completo\n",
    "best_model_random.fit(df_train_cleaned[selected_features_extended], df_train_cleaned['Clicks'])\n",
    "\n",
    "# Calcular el RMSE en el conjunto de entrenamiento\n",
    "train_predictions_random = best_model_random.predict(df_train_cleaned[selected_features_extended])\n",
    "train_rmse_random = np.sqrt(mean_squared_error(df_train_cleaned['Clicks'], train_predictions_random))\n",
    "print(\"RMSE en el conjunto de entrenamiento con el mejor modelo de la búsqueda aleatoria:\", train_rmse_random)\n",
    "\n",
    "# Calcular el RMSE en el conjunto de validación utilizando el mejor modelo de la búsqueda aleatoria\n",
    "valid_predictions_random = best_model_random.predict(X_valid)\n",
    "valid_rmse_random = np.sqrt(mean_squared_error(y_valid, valid_predictions_random))\n",
    "print(\"RMSE en el conjunto de validación con el mejor modelo de la búsqueda aleatoria:\", valid_rmse_random)\n",
    "\n",
    "# Verificar sobreajuste comparando el RMSE en el conjunto de entrenamiento y el conjunto de validación\n",
    "if train_rmse_random < valid_rmse_random:\n",
    "    print(\"El modelo con los mejores hiperparámetros podría estar sobreajustado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4efc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
